{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-mailig', 'breast', 'irradiat', 'target']\n",
    "df = pd.read_csv('breast cancer.csv', header=None, names=columns)\n",
    "df['target'] = df['target'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the values are normalized from 0 to 1\n",
    "\n",
    "## Feature visualization\n",
    "Let's plot the distributions of the features, conditioned on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(20, 20))\n",
    "axs = axs.flatten()\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.histplot(data=df, x=col, hue='target', kde=True, palette='Set1', ax=axs[i])\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was unable to determine names of features but the following set seems possible and found descriptions of the features:\n",
    "- 0 - menopause - 12 months after a women’s final period.\n",
    "- 1 - tumor-size - the size of the cancer tumor at the time of diagnosis.\n",
    "- 2 - inv-nodes - number of lymph nodes in the armpit that contain the spread of breast cancer visible.\n",
    "- 3 - node-caps - though the outside of the tumor seems to be contained cancer may expose the risk of metastasis to the lymph node.\n",
    "- 4 - deg-malig - Degree of malignancy – Grade of cancer that is visible under a microscope.\n",
    "- 5 - breast - which side of the breast, does breast cancer occur.\n",
    "- 6 - irradiat - Irradiation: treatment that destroys cancer cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target')\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more instances with a class: *no-recurrence-events* (0) than *recurrence-events* (1).\\\n",
    "In fact there are roughly 70% instances of 0 and 30% instances of 1. So our baseline accuracy is 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the results aren't very satisfying as we only slightly improved the baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=0.8)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the intercept is below zero, so the model is biased towards predicting *no-recurrence-events* (0), which makes sense as it is the **majority class**.\n",
    "\n",
    "## Weight visualization\n",
    "\n",
    "Let's plot the values for coefficients of the model to see which features are the most influencial in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=X_train.columns, height=clf.coef_[0])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Logistic regression weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values,\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['no-recurrence-events', 'recurrence-events'],\n",
    "    discretize_continuous=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations of the decisions\n",
    "### First instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = X_test.iloc[0]\n",
    "explanation = explainer.explain_instance(\n",
    "    instance.values,\n",
    "    clf.predict_proba,\n",
    "    num_features=5\n",
    ")\n",
    "\n",
    "explanation.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this patient has the smallest possible value of node-caps, which is an influential feature in the model. The degree of malignancy is quite high which influences the model into predicting *recurrence-events* (1). However rest of the features also seem quite low which might be the reason why the model is biased towards predicting *no-recurrence-events* (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = sum([clf.coef_[0][i] * instance[col] for i, col in enumerate(X_train.columns)]) + clf.intercept_\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_CAPS = 4\n",
    "val / clf.coef_[0][NODE_CAPS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory if we change the value of node-caps to around -0.65 we should observe the change of class. Let's check what happens after sampling such instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = instance.copy()\n",
    "instance['node-caps'] = 0.7\n",
    "explanation = explainer.explain_instance(\n",
    "    instance.values,\n",
    "    clf.predict_proba,\n",
    "    num_features=5\n",
    ")\n",
    "\n",
    "explanation.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second instance (most in the direction of benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = X_test.iloc[67]\n",
    "explanation = explainer.explain_instance(\n",
    "    instance.values,\n",
    "    clf.predict_proba,\n",
    "    num_features=7\n",
    ")\n",
    "\n",
    "explanation.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took the example for which the model predicted the highest probability of 0 (no-recurrence-events). As you can see basically all features with positive coefficients have low values while breast (the only one with negative coeff) has a high value. Overall adding the model of the bias we are obtaining a very low value which is equivalent to the model predicting 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = X_test.iloc[42]\n",
    "explanation = explainer.explain_instance(\n",
    "    instance.values,\n",
    "    clf.predict_proba,\n",
    "    num_features=7\n",
    ")\n",
    "\n",
    "explanation.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example for which the model predicted the highest probability of 1 (recurrence-events). As you can see the values of the most important features are quite high. Node-caps, deg-mailig and menopause all obtain the highest value possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = instance.copy()\n",
    "instance['node-caps'] = 0\n",
    "explanation = explainer.explain_instance(\n",
    "    instance.values,\n",
    "    clf.predict_proba,\n",
    "    num_features=7\n",
    ")\n",
    "\n",
    "explanation.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this patient we cannot change the decision of the model by just modifying one feature. As all other features are \"working\" in favor of predicting 1, we would need to change multiple features to change the prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
